{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7665d735-04cb-4819-93a1-3913ea65eed9",
   "metadata": {},
   "source": [
    "# Assign integer index to H3 cells using group_by for node assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb33254-17d8-4df1-8a44-c59d033fa00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for compatability.....\n",
    "# !pip install polars, rustworkx, pytorch, feature-engineering-polars==0.2.0\n",
    "\n",
    "\n",
    "import os\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "# import cugraph\n",
    "import rustworkx as rx\n",
    "import cdlib\n",
    "import networkx as nx\n",
    "\n",
    "import pyvis as pv\n",
    "\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceadd567-ebb5-4ed4-818c-855741036a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = '/mnt/c/Users/Asus/Code/data/AIS/enriched_AIS'\n",
    "data = [file for file in os.listdir(data_folder) if 'parquet' in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b5e7ed-ab09-48e6-954a-7e9bb462eaf3",
   "metadata": {},
   "source": [
    "# Communities for a geospatial result | edges are MMSI<->H3_cell\n",
    "### results should be communities of vessls with similar destinations/routs, or whatever it is boats do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70e93ad3-61c1-4f14-adea-2463e26fab99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THIS is how we will assign H3 indexes\n",
    "# just remember to delete at the end, otherwise better off with a hash table or something\n",
    "# polars for ETL: be sure to do lazy or streaming for query optimization\n",
    "ais =  (\n",
    "    pl.concat(\n",
    "        [dat for dat in \n",
    "         [pl.scan_parquet(f\"\"\"{data_folder}{os.sep}{file}\"\"\") \n",
    "          for file in data \n",
    "          if 'parquet' in file] \n",
    "         if 'LON' in dat.columns]\n",
    "    , how='diagonal'\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.col('BaseDateTime').str.strptime(pl.Datetime, format='%Y-%m-%dT%H:%M:%S'))\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "INDEX_OFFSET = len(ais.select(pl.col('H3')).unique().collect())\n",
    "# now get our edges (and nodes), by grouping on MMSI and H3 cells\n",
    "ais = (\n",
    "    ais\n",
    "    .group_by(pl.col('H3'))\n",
    "    .agg(pl.all())\n",
    "    .with_row_index(name='H3_index')\n",
    "    .explode(pl.exclude(['H3','H3_index']))\n",
    "    .group_by(pl.col('MMSI'))\n",
    "    .agg(pl.all())    \n",
    "    .with_row_index(\n",
    "        name='MMSI_index', \n",
    "        offset=INDEX_OFFSET)\n",
    "    .explode(pl.exclude(['MMSI','MMSI_index']))\n",
    "    .group_by(pl.col(['H3_index', 'MMSI_index']))\n",
    "    .agg(pl.all())\n",
    "    .explode(pl.exclude(['H3_index', 'MMSI_index']))\n",
    "    .with_columns(\n",
    "        pl.struct(pl.col(['H3_index', 'MMSI_index'])).alias('edge'))\n",
    "    .with_columns(\n",
    "        pl.col(['H3_index', 'MMSI_index']).cast(pl.Int64))\n",
    "    .select(\n",
    "        pl.col(['H3','MMSI', 'H3_index','MMSI_index', 'LON','LAT', 'BaseDateTime']))\n",
    ").collect()\n",
    "\n",
    "\n",
    "# farts, lat and long are flipped in the ETL somehow.....\n",
    "ais = ais.with_columns(pl.col('LON').alias('latitude')).with_columns(pl.col('LAT').alias('longitude'))\n",
    "ais = ais.with_columns(pl.col('longitude').alias('LON')).with_columns(pl.col('latitude').alias('LAT'))\n",
    "\n",
    "edge_table = ais.select(pl.col(['H3', 'MMSI', 'BaseDateTime'])).group_by(pl.col(['H3','MMSI'])).len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f42fe8-7781-4493-9eec-9d71971b23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpi = pl.read_csv('/mnt/d/data/Ports/major_ports.csv').drop('OBJECTID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e8ab82b-291a-480d-bebb-fbbcd6d9a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "password = 'wdi85v#MvBJZ4#M'\n",
    "account = 'nightwatch'\n",
    "\n",
    "# xml return\n",
    "# url = f\"http://api.geonames.org/findNearbyPlaceName?lat=47.3&lng=9&username={account}\"\n",
    "\n",
    "def get_PlaceName(\n",
    "    latitude,\n",
    "    longitude,\n",
    "    verbose=False\n",
    "):\n",
    "    \n",
    "    # url = f\"http://api.geonames.org/findNearbyPlaceNameJSON?lat={latitude}&lng={longitude}&username={account}\"\n",
    "    url = f\"\"\"http://api.geonames.org/findNearbyPlaceNameJSON?lat={latitude}&lng={longitude}&radius=300&username={account}\"\"\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(type(latitude), latitude)\n",
    "        print(url)\n",
    "        \n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    \n",
    "    else:\n",
    "        return response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c501482-97e8-4557-9359-a0491a8062c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46243"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limit the query to geonames by binning in H3 cells\n",
    "H3_MASK = 68\n",
    "\n",
    "ais = (\n",
    "    ais.with_columns(\n",
    "        pl.col('H3').str.slice(0, H3_MASK)\n",
    "        .alias('H3_MASK')))\n",
    "\n",
    "coordinates = (\n",
    "    ais.group_by(pl.col('H3_MASK'))\n",
    "    .agg(pl.col(['LON', 'LAT']).mean())\n",
    ")\n",
    "len(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60a3cbc6-cb92-4f97-b8c2-c649fa3527f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (46_243, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>H3_MASK</th><th>LON</th><th>LAT</th><th>response</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>str</td></tr></thead><tbody><tr><td>&quot;872913204fffff…</td><td>34.670242</td><td>-121.163035</td><td>&quot;{&quot;status&quot;:{&quot;me…</td></tr><tr><td>&quot;872819a66fffff…</td><td>43.115434</td><td>-125.735206</td><td>&quot;{&quot;status&quot;:{&quot;me…</td></tr><tr><td>&quot;872922412fffff…</td><td>30.358475</td><td>-123.4595</td><td>&quot;{&quot;status&quot;:{&quot;me…</td></tr><tr><td>&quot;87291a208fffff…</td><td>36.32935</td><td>-122.476929</td><td>&quot;{&quot;status&quot;:{&quot;me…</td></tr><tr><td>&quot;87281d3b6fffff…</td><td>42.387796</td><td>-125.063012</td><td>&quot;{&quot;status&quot;:{&quot;me…</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;8729181aafffff…</td><td>35.28424</td><td>-123.0902</td><td>null</td></tr><tr><td>&quot;8728f1a1efffff…</td><td>45.839067</td><td>-124.496667</td><td>null</td></tr><tr><td>&quot;87280440dfffff…</td><td>39.220116</td><td>-124.233712</td><td>null</td></tr><tr><td>&quot;8728c4036fffff…</td><td>46.237376</td><td>-125.255454</td><td>null</td></tr><tr><td>&quot;8728c4674fffff…</td><td>46.640593</td><td>-125.31607</td><td>null</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (46_243, 4)\n",
       "┌─────────────────┬───────────┬─────────────┬───────────────────────────────────┐\n",
       "│ H3_MASK         ┆ LON       ┆ LAT         ┆ response                          │\n",
       "│ ---             ┆ ---       ┆ ---         ┆ ---                               │\n",
       "│ str             ┆ f64       ┆ f64         ┆ str                               │\n",
       "╞═════════════════╪═══════════╪═════════════╪═══════════════════════════════════╡\n",
       "│ 872913204ffffff ┆ 34.670242 ┆ -121.163035 ┆ {\"status\":{\"message\":\"invalid us… │\n",
       "│ 872819a66ffffff ┆ 43.115434 ┆ -125.735206 ┆ {\"status\":{\"message\":\"invalid us… │\n",
       "│ 872922412ffffff ┆ 30.358475 ┆ -123.4595   ┆ {\"status\":{\"message\":\"invalid us… │\n",
       "│ 87291a208ffffff ┆ 36.32935  ┆ -122.476929 ┆ {\"status\":{\"message\":\"invalid us… │\n",
       "│ 87281d3b6ffffff ┆ 42.387796 ┆ -125.063012 ┆ {\"status\":{\"message\":\"invalid us… │\n",
       "│ …               ┆ …         ┆ …           ┆ …                                 │\n",
       "│ 8729181aaffffff ┆ 35.28424  ┆ -123.0902   ┆ null                              │\n",
       "│ 8728f1a1effffff ┆ 45.839067 ┆ -124.496667 ┆ null                              │\n",
       "│ 87280440dffffff ┆ 39.220116 ┆ -124.233712 ┆ null                              │\n",
       "│ 8728c4036ffffff ┆ 46.237376 ┆ -125.255454 ┆ null                              │\n",
       "│ 8728c4674ffffff ┆ 46.640593 ┆ -125.31607  ┆ null                              │\n",
       "└─────────────────┴───────────┴─────────────┴───────────────────────────────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places = (\n",
    "    coordinates\n",
    "    .with_columns(\n",
    "        pl.struct(\n",
    "            pl.col(['LON','LAT']))\n",
    "        .map_elements(\n",
    "            lambda xx: get_PlaceName(xx['LON'], xx['LAT']))\n",
    "    .alias('response'))\n",
    "    # .unnest('response')\n",
    "    # .explode(pl.col('geonames'))\n",
    "    # .unnest('geonames')\n",
    "    # .unnest('adminCodes1')\n",
    ")\n",
    "places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976dbec8-1dbe-4070-9ea9-f45e444b387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ais.join(places, how='left', on='H3_MASK')\n",
    "places = places.unnest('response').explode(pl.col('geonames')).unnest('geonames').unnest('adminCodes1')\n",
    "\n",
    "PLACES_FILEPATH = '/mnt/d/data/Ports/ais_places.parquet'\n",
    "places.write_parquet(PLACES_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e34ddb0-863c-4192-9189-eeba79fb0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vincenty import vincenty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252ddf74-5321-49c5-bc11-d31a84e61172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ais_temp = ais.group_by('H3_MASK').agg(pl.all())\n",
    "# places_temp = places.drop_nulls().group_by('H3_MASK').agg(pl.all())\n",
    "\n",
    "# temp = {}\n",
    "# for H3 in ais['H3_MASK'].unique():\n",
    "#     AT = ais_temp.filter(pl.col('H3_MASK') == H3)\n",
    "#     PT = places_temp.filter(pl.col('H3_MASK') == H3)\n",
    "#     if len(AT) > 0 and len(PT) >1:\n",
    "#         temp[H3] = AT.join(PT, how='left', on='H3_MASK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b188c0-72a6-4f74-894d-61b3221899a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# places.filter(pl.col('lng').is_not_null() & pl.col('lat').is_not_null()).group_by('H3_MASK').agg(pl.all())\n",
    "places.drop_nulls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57bb58b-a9d9-44fa-9224-376cae270f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import rustworkx as rx\n",
    "from cdlib import algorithms, evaluation, viz\n",
    "\n",
    "import hvplot.networkx as hvnx\n",
    "\n",
    "from pyvis.network import Network\n",
    "from pyvis import network as net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06678be7-acdb-4d3b-ae7e-713f67903ab9",
   "metadata": {},
   "source": [
    "# NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb21508-1743-4bb7-ac5b-936e4c8305bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_G = nx.Graph()\n",
    "\n",
    "for e in edge_table.to_numpy():\n",
    "    nx_G.add_edge(e[0]['H3_index'], e[0]['MMSI_index'], weight=e[1])\n",
    "\n",
    "# different algorithms\n",
    "louvain_coms = algorithms.louvain(nx_G)\n",
    "\n",
    "lp_coms = algorithms.label_propagation(nx_G)\n",
    "\n",
    "evaluation.normalized_mutual_information(louvain_coms, lp_coms)\n",
    "\n",
    "# too big to plot\n",
    "# viz.plot_community_graph(\n",
    "#     nx_G, # graph – NetworkX/igraph graph\n",
    "#     louvain_coms, # partition – NodeClustering object\n",
    "#     figsize=(15.0,15.0), #– the figure size; it is a pair of float, default (8, 8)\n",
    "#     node_size=200, #– int, default 200\n",
    "#     plot_overlaps=False, #– bool, default False. Flag to control if multiple algorithms memberships are plotted.\n",
    "#     plot_labels=True, #– bool, default False. Flag to control if node labels are plotted.\n",
    "#     cmap=None, #– str or Matplotlib colormap, Colormap(Matplotlib colormap) for mapping intensities of nodes. If set to None, original colormap is used..\n",
    "#     top_k=10, #– int, Show the top K influential communities. If set to zero or negative value indicates all.\n",
    "#     min_size=10, #– int, Exclude communities below the specified minimum size\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8a749-caeb-4f4f-92d2-a45e35fe3b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alright, so lets look at these ourselves....\n",
    "communities = {\n",
    "    int(f\"{len(com)}{i}\"):com for i, com in enumerate(louvain_coms.communities)\n",
    "}\n",
    "\n",
    "biggest = communities[max(communities.keys())]\n",
    "\n",
    "biggest = ais.filter(\n",
    "    pl.col('H3_index').is_in(biggest)\n",
    "    | pl.col('MMSI_index').is_in(biggest)\n",
    ").groupby(pl.col('edge')).agg(pl.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9c2b09-ad74-4d56-aff0-f40936cd81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def pl_to_nx(\n",
    "    frame\n",
    "):\n",
    "    frame = frame.select(pl.col(['H3_index', 'MMSI_index', 'BaseDateTime'])).groupby(pl.col(['H3_index','MMSI_index'])).count()\n",
    "    graph = nx_G = nx.Graph()\n",
    "    \n",
    "    for e in frame.to_numpy():\n",
    "        graph.add_edge(\n",
    "            e[0], \n",
    "            e[0], \n",
    "            weight=e[1]\n",
    "        )\n",
    "    \n",
    "    return graph\n",
    "\n",
    "b_nx_G = pl_to_nx(ais)\n",
    "hvnx.draw(b_nx_G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571e14b-ef0a-4e50-ba36-e6e4918c11bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7a64c4-efeb-48f3-b806-c848c0592945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4ffa0-30da-482d-8346-f58dff79c90b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_table.groupby('MMSI').agg(pl.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ba08c-3131-4d35-bdb1-e57851084ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import pandas as pd\n",
    "\n",
    "got_net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "# set the physics layout of the network\n",
    "got_net.barnes_hut()\n",
    "\n",
    "sources = edge_table['MMSI']\n",
    "targets = edge_table['H3']\n",
    "weights = edge_table['count']\n",
    "\n",
    "edge_data = zip(sources, targets, weights)\n",
    "\n",
    "for e in edge_data:\n",
    "                src = e[0]\n",
    "                dst = e[1]\n",
    "                w = e[2]\n",
    "                got_net.add_node(src, src, title=src)\n",
    "                got_net.add_node(dst, dst, title=dst)\n",
    "                got_net.add_edge(src, dst, value=w)\n",
    "\n",
    "neighbor_map = got_net.get_adj_list()\n",
    "\n",
    "# add neighbor data to node hover data\n",
    "for node in got_net.nodes:\n",
    "                node[\"title\"] += \" Neighbors:<br>\" + \"<br>\".join(neighbor_map[node[\"id\"]])\n",
    "                node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "\n",
    "got_net.show(\"ais.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561f139-48cd-4a7a-b5ca-0e3a141fd082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm eval metrics\n",
    "# louvain_coms.normalized_mutual_information(lp_coms)\n",
    "\n",
    "# louvain_coms.average_internal_degree()\n",
    "# evaluation.average_internal_degree(nx_G, louvain_coms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ad3f48-3c34-4a18-86bf-661e8f8a078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# community labels\n",
    "# lp_coms.communities\n",
    "\n",
    "# these are the community assignments per node\n",
    "# louvain_coms.to_node_community_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130958ad-8ce5-4c9e-9c03-c0dea903dd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with pyvis\n",
    "pos = nx.spring_layout(nx_G)\n",
    "# viz.plot_network_clusters(nx_G, louvain_coms, pos)\n",
    "\n",
    "\n",
    "\n",
    "# viz.plot_network_clusters(nx_G, louvain_coms, pos, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8207b-cf58-4f53-a613-b38f2750d082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with hvplot/bokeh\n",
    "\n",
    "hvnx.draw(nx_G, with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a992a-822a-4c8e-ae28-6021b626d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "net.add_nodes(\n",
    "    [1,2,3], \n",
    "    value=[10, 100, 400],\n",
    "    title=['I am node 1', 'node 2 here', 'and im node 3'],\n",
    "    x=[21.4, 54.2, 11.2],\n",
    "    y=[100.2, 23.54, 32.1],\n",
    "    label=['NODE 1', 'NODE 2', 'NODE 3'],\n",
    "    color=['#00ff1e', '#162347', '#dd4b39']\n",
    ")\n",
    "\n",
    "net.add_edge(0, 1, weight=.87)\n",
    "net.toggle_physics(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9cca0-71e4-4839-bc07-0eb60152af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(height=\"750px\", width=\"100%\", bgcolor=\"#222222\", font_color=\"white\")\n",
    "\n",
    "# set the physics layout of the network\n",
    "net.barnes_hut()\n",
    "\n",
    "source_label = geo['H3']\n",
    "sources = geo['H3_index']\n",
    "target_label = geo['MMSI']\n",
    "targets = geo['MMSI_index']\n",
    "weights = geo['count']\n",
    "\n",
    "edge_data = list(zip(sources, source_label, targets, target_label, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e525a-1955-4596-a4c8-a471f62ae9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in edge_data:\n",
    "    src = e[0]\n",
    "    src_l = e[1]\n",
    "    tgt = e[2]\n",
    "    tgt_l = e[3]\n",
    "    w = e[4]\n",
    "    \n",
    "    net.add_node(src, src, title=src_l)\n",
    "    net.add_node(tgt, tgt, title=tgt_l)\n",
    "    net.add_edge(src, tgt, value=w)\n",
    "\n",
    "neighbor_map = net.get_adj_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e8f1d-dcdd-451c-8a36-f3a37c6e9ef7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "# net.set_options('''\n",
    "# var options = {\n",
    "#     \"nodes\": {\n",
    "#     \"borderWidth\": 2,\n",
    "#     \"borderWidthSelected\": 4\n",
    "#   },\n",
    "#   \"edges\":{\n",
    "#     \"width\":24\n",
    "#   },\n",
    "#   \"physics\": {\n",
    "#     \"barnesHut\": {\n",
    "#       \"gravitationalConstant\":-2000,\n",
    "#       \"centralGravity\": 0,\n",
    "#       \"springLength\": 60,\n",
    "#       \"springConstant\": 0.545,\n",
    "#       \"damping\": 0.1,\n",
    "#       \"avoidOverlap\": 0.52\n",
    "#     },\n",
    "#     \"maxVelocity:\":50,\n",
    "#     \"minVelocity\": 0.75,\n",
    "#     \"timestep\": 0.5\n",
    "#   }\n",
    "# }\n",
    "# ''')\n",
    "\n",
    "# for atomo in range(14): \n",
    "#     net.add_node(\n",
    "#         atomo,\n",
    "#         label=ids[atomo],\n",
    "#         x=int(100*xs[atomo]),\n",
    "#         y=int(100*ys[atomo]),\n",
    "#         physics=True,\n",
    "#         size=30)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b7aeb-9da4-444c-8481-f9c4f4c9529f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add neighbor data to node hover data\n",
    "# for node in net.nodes:\n",
    "#     node[\"title\"] += \" Neighbors:<br>\" + \"<br>\".join(neighbor_map[node[\"id\"]])\n",
    "#     node[\"value\"] = len(neighbor_map[node[\"id\"]])\n",
    "\n",
    "net.show(\"AIS_communities.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7f49fb-8944-441b-b45d-64294c581091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_nodes_input(\n",
    "    frame, \n",
    "    node_column='index', \n",
    "    weight_column=None,\n",
    "    int_only=False\n",
    "):\n",
    "    if int_only == True:\n",
    "        [i for i in geo[[node_column]].unique()[node_column]]\n",
    "        \n",
    "    elif weight_column != None:\n",
    "        print('weights not implemented')\n",
    "        return [(i, None) for i in geo[[node_column]].unique()[node_column]]\n",
    "    else:\n",
    "        return [(i, None) for i in geo[[node_column]].unique()[node_column]]\n",
    "    \n",
    "def make_edge_input(\n",
    "    frame, \n",
    "    edge_column_A='index_A', \n",
    "    edge_column_B='index_B', \n",
    "    weight_column=None\n",
    "):\n",
    "    if weight_column != None:\n",
    "        print('weights not implemented')\n",
    "        \n",
    "    edges = (frame.lazy()\n",
    "             .select(pl.col([edge_column_A,edge_column_B]))\n",
    "             .unique()\n",
    "             .select(\n",
    "                 pl.concat_list(\n",
    "                     pl.col([edge_column_A,edge_column_B]))\n",
    "                 .alias('edge'))\n",
    "            ).collect().to_numpy()\n",
    "    \n",
    "    return [(edge[0][0], edge[0][1], None) for edge in edges]\n",
    "\n",
    "# for weighted edges..... use one of the aggregations instead of None in the 3rd place, or combination\n",
    "edges = make_edge_input(geo, edge_column_A='MMSI', edge_column_B='H3_index') # (node1, node2, payload)\n",
    "try:\n",
    "    edge_indicies = G.add_edges_from(edges)\n",
    "except:\n",
    "    print('Failed to add all edges - adding individually...')\n",
    "    failures = []\n",
    "    for edge in edges:\n",
    "        try:\n",
    "            G.add_edge(edge)\n",
    "        except:\n",
    "            failures.append(edge)\n",
    "    print('Successfully added:', len(edges)-len(failures), '\\nFailed:', len(failures))\n",
    "# edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11304fa-041e-49f3-9e6e-12a8e8c5c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community Discovery algorithm(s) selection and configuration\n",
    "\n",
    "# Clustering(s) evaluation (Fitness functions)\n",
    "\n",
    "# Clustering(s) evaluation (Comparisons)\n",
    "\n",
    "# Community/Statistics Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a1732-1f5c-4667-a909-ead1b95b0b09",
   "metadata": {},
   "source": [
    "# RustworkX\n",
    "https://www.rustworkx.org/tutorial/introduction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28107f9a-692a-4638-8e77-c6fac3725ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rustworx for network creation: nodes=MMSI, edges=H3\n",
    "rx_G = rx.PyGraph()\n",
    "\n",
    "\n",
    "# rx_G.add_edge\n",
    "\n",
    "# add nodes\n",
    "# h3_nodes = make_nodes_input(geo, node_column='H3_index', int_only=False)\n",
    "# mmsi_nodes = make_nodes_input(geo, node_column='MMSI', int_only=False)\n",
    "\n",
    "# or add them directly and save the computation\n",
    "# M_node_indicies = G.add_nodes_from(mmsi_nodes)\n",
    "# H_node_indicies = G.add_nodes_from(h3_nodes)\n",
    "# node_indicies = G.add_nodes_from(h3_nodes+mmsi_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78b68a-b92f-4d90-9052-647e7be3093b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set([e[0] for e in edges if type[0] != float])\n",
    "# # set([e[1] for e in edges])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c2186-ed58-45d5-a190-c68bb5e9cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.add_edge(edges[0])\n",
    "# edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a057f-dbb0-4425-abf2-61cbe16ea34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G.num_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a5c4ba-c10f-4e01-bbc3-a72d0eef5c46",
   "metadata": {},
   "source": [
    "# Communities of vessels with intersections in space and time | ie. meetings\n",
    "### done for a poxy of communications relationship results we need MMSI<->MMSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82210a-2991-4d59-9365-5389129db4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we have no comms link, we will use colocation in an h3 cell on the same day as a proxy\n",
    "# - this does not represent a true proxy, but the structure will be right and it could be considered a meeting? so sort of\n",
    "com = (\n",
    "    df.lazy()\n",
    "    .with_columns(pl.col('BaseDateTime').cast(pl.Date).cast(pl.Utf8).alias('Date'))\n",
    "    .groupby(\n",
    "        pl.col(['H3', 'Date']))\n",
    "    .agg(pl.all())\n",
    "    .with_row_count(name='edge_index')\n",
    "    .explode(pl.exclude(['H3','Date', 'edge_index']))\n",
    ").collect()\n",
    "com.filter(pl.col('edge_index')==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd11a7f-6e9d-47a6-b99b-4d626b85c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from cdlib import algorithms\n",
    "\n",
    "G = nx.MultiGraph()\n",
    "\n",
    "algorithms.louvain(G, weight=None, resolution=1, randomize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980e631-ac12-4994-be34-8e5ffdcbf6ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# edges = (df#.lazy()\n",
    "#          .select(pl.col(['MMSI','H3']))\n",
    "#          .select(\n",
    "#              pl.concat_str(\n",
    "#                  pl.col(['MMSI','H3']))\n",
    "#              .alias('edge'))\n",
    "#          .groupby(\n",
    "#              pl.col('edge'))\n",
    "#          .agg(pl.col('edge').count().alias('edge_count'))\n",
    "#         )#.collect()\n",
    "\n",
    "edges = (\n",
    "    df.lazy()\n",
    "    # isolate edges as an edge label to get aggregations for a payload if desired\n",
    "    .with_columns(\n",
    "        # combine the edge as a string initially, syntax is simpler and query optimization will eliminate the excess in the end\n",
    "        pl.concat_str(pl.col(['MMSI','H3'])).alias('edge_label'),\n",
    "        pl.col('H3').apply(lambda x: hash(x) + sys.maxsize + 1).alias('H3_index'),\n",
    "    \n",
    "        # if we want to get the number of days an edge was seen, best to change dtype before the aggregation\n",
    "        pl.col('BaseDateTime').cast(str).str.slice(0,10).alias('date')) \n",
    "    # get the edge counts as to use as edge weight - use whatever aggregation you like, there are a couple examples\n",
    "    .groupby('edge_label')\n",
    "    .agg(\n",
    "        pl.col('MMSI').unique().first().cast(pl.Int64),\n",
    "        pl.col('H3').unique().first(),\n",
    "        pl.col('H3_index').unique().first(),\n",
    "        pl.col('edge_label').count().alias('edge_count'),\n",
    "        pl.col('date').n_unique().alias('days_edge_seen'),\n",
    "        pl.col('VoyageID').n_unique().alias('total_voyages'),\n",
    "    )\n",
    "    # .with_columns(pl.col('edge')) # may be a more elegent way, but with the query optimization we dont need to do it\n",
    ").collect()\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a301723-7ce3-42ab-8d39-c6871ab22c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_directional_arcs(\n",
    "    num_arcs, \n",
    "    return_as='list'\n",
    "):\n",
    "    \"\"\"\n",
    "    get_directional_arcs finds the left and right degree extents for the arc of a cardinal direction,\n",
    "        or... with inputs greater than 4, sub-ranges for things like SW\n",
    "    \"\"\"\n",
    "    cardinals = ['N', 'E', 'S', 'W']\n",
    "    \n",
    "    if num_arcs%4 != 0:\n",
    "        print('num_arcs must be a multiple of 4, for now....')\n",
    "        return None\n",
    "        \n",
    "    # get the span of the arc\n",
    "    arc_length  = 360/num_arcs \n",
    "\n",
    "    card_arcs = []\n",
    "    card_dict = {}\n",
    "    \n",
    "    for i in range(0,num_arcs):\n",
    "        if i == 0:\n",
    "            card_arcs.append([360-(arc_length/2), 0+arc_length/2])\n",
    "        elif i == 1:\n",
    "            card_arcs.append((card_arcs[i-1][0]+arc_length-360, card_arcs[i-1][1]+arc_length))\n",
    "        else:\n",
    "            card_arcs.append((card_arcs[i-1][0]+arc_length, card_arcs[i-1][1]+arc_length))\n",
    "            \n",
    "    return card_arcs\n",
    "\n",
    "card_directions = get_directional_arcs(8)\n",
    "\n",
    "# use cardinal directions....\n",
    "\n",
    "# card = (\n",
    "#     edges.lazy()\n",
    "#     .with_columns(\n",
    "#         pl.when(pl.col('Heading'))\n",
    "#         pl.col('Heading')\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0418a17c-f5b4-4baa-91bb-b501e6e87fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rustworkx takes tuples.....\n",
    "\n",
    "e = [tuple(i) for i in edges[[\n",
    "    'MMSI','H3_index', \n",
    "    'edge_count'\n",
    "]].to_numpy()]\n",
    "e[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fdb700-b9d9-431d-a5bf-25e0dc5a2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a graph\n",
    "\n",
    "G = rx.PyGraph()\n",
    "G.add_edges_from(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f06e93-3c8a-4ff9-8ac6-f410d258d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Community Discovery\n",
    "\n",
    "\"\"\" CDlib - Community Detection Library\n",
    "https://cdlib.readthedocs.io/en/latest/tutorial.html\n",
    "https://cdlib.readthedocs.io/en/latest/reference/reference.html\n",
    "https://cdlib.readthedocs.io/en/latest/reference/cd_algorithms/node_clustering.html\n",
    "\"\"\"\n",
    "# import cdlib\n",
    "from cdlib import algorithms, evaluation\n",
    "import networkx as nx\n",
    "import rustworkx as rx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ee40f4-dd8f-4538-a929-e48d5747cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Community Objects\n",
    "NodeClustering: \n",
    "    Node communities (either crisp partitions or overlapping groups);\n",
    "FuzzyNodeClustering: \n",
    "    Overlapping node communities with explicit node to community belonging score\n",
    "BiNodeClustering: \n",
    "    Clustering of a Bipartite graphs (with the explicit representation of class homogeneous communities);\n",
    "AttrNodeClustering: \n",
    "    Clustering of feature-rich (node-attributed) graphs;\n",
    "\n",
    "EdgeClustering: \n",
    "    Edge communities;\n",
    "TemporalClustering: \n",
    "    Clustering of Temporal Networks;\n",
    "'''\n",
    "\"\"\" Community Discovery\n",
    "Algorithms - and their parameters\n",
    "    https://cdlib.readthedocs.io/en/latest/reference/cd_algorithms/algorithms.html\n",
    "\n",
    "Network Complexity Notation\n",
    "    n: number of nodes\n",
    "    m: number of edges\n",
    "    k: number of iterations\n",
    "    c: number of communities\n",
    "    d: average node degree\n",
    "\n",
    "Network parameters\n",
    "    Directed\n",
    "    Weighted\n",
    "    Bipartite\n",
    "    Feature Rich\n",
    "    Temporal\n",
    "    \n",
    "Communities\n",
    "    Crisp\n",
    "    Overlaps\n",
    "    Nested\n",
    "    Fuzzy\n",
    "    Hierachical\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0365003-307e-4330-995c-afe7a29b1edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "https://pyvis.readthedocs.io/en/latest/tutorial.html\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b324f-230c-4b10-ad98-894e4291740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional library\n",
    "import communities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2120f-3b61-4a21-9909-ee04be4be5f7",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c808f-db10-4b56-8d9e-ce0dc38d112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "cdlib - community discovery workflow\n",
    "\n",
    "https://towardsdatascience.com/graphs-with-python-overview-and-best-libraries-a92aa485c2f8\n",
    "\n",
    "cugraph 300x faster than networkx - but needs GPU\n",
    "    https://medium.com/rapids-ai/rapids-cugraph-1ab2d9a39ec6#:~:text=RAPIDS%20cuDF%20%2B%20cuGraph%20is%20300x,is%203400x%20faster%20than%20NetworkX.\n",
    "\n",
    "rustworkx 6 - 120x faster than networkx depending on operation - CPU\n",
    "    https://qiskit.org/ecosystem/rustworkx/networkx.html\n",
    "    \n",
    "polars query optimization makes its speed rival cudf\n",
    "    \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2adc097-86c8-4a02-be6e-224e3e509ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "142/6\n",
    "14.1/.11\n",
    "136/6.1\n",
    "320/49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be613c3-4073-4c8e-b90a-a2a43599822b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parliament",
   "language": "python",
   "name": "parliament"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
